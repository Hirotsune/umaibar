{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Latent Me.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yasudakn/umaibar/blob/master/Latent_Me.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YKkEsqfBMdNj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save a Copy (File -> Save a copy in Drive) to run"
      ]
    },
    {
      "metadata": {
        "id": "Ubpsx_r8-vhv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Finding yourself in the latent space of StyleGAN\n",
        "\n",
        "Dmitry Nikitko (puzer) wrote [the original code](https://github.com/Puzer/stylegan) for this notebook which extends the work released by NVidia on StyleGAN. I have modified and annotated it to make it easier to use in Colab. After running through this notebook you should have a StyleGAN generated image (or set of images) which closely match photos of you that you've uploaded.\n",
        "\n",
        "You'll also have a `npy` file which is the latent code (or location) of your image in the StyleGAN latent space."
      ]
    },
    {
      "metadata": {
        "id": "frBc9Kl2ALv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ead78888-8b37-40f5-c040-c891a48d3ebf"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Puzer/stylegan"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan'...\n",
            "remote: Enumerating objects: 105, done.\u001b[K\n",
            "remote: Total 105 (delta 0), reused 0 (delta 0), pack-reused 105\u001b[K\n",
            "Receiving objects: 100% (105/105), 10.24 MiB | 11.73 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RnWcHKIiAkAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ea631b56-ce00-4f1a-dcf8-88d71c7bf725"
      },
      "cell_type": "code",
      "source": [
        "%cd stylegan\n",
        "# Use the version this notebook was built with\n",
        "!git checkout c3fb250c65840c8837ded78e34485227755c2473"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/stylegan\n",
            "Note: checking out 'c3fb250c65840c8837ded78e34485227755c2473'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at c3fb250 Update README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2qQSqipARWtB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir raw_images aligned_images generated_images latent_representations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ppy24iTjSKAy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Add your image(s)\n",
        "\n",
        "Upload your image using the Sidebar now. \n",
        "\n",
        "To open the sidebar select \"View\" and then \"Table of Contents\".\n",
        "\n",
        "The sidebar should now be open. Click the \"Files\" tab.\n",
        "\n",
        "Before uploading make sure:\n",
        "\n",
        "1.   The image(s) you're using can be opened by PIL (jpg, png, etc)\n",
        "2.   The images are larger than 1024x1024. Preferably significantly larger so the aligner can crop out a high resolution section of the image containing your face.\n",
        "3.   Your face in the image is well lit and facing the camera (for best results)\n",
        "\n",
        "Click ''Upload\" in the sidebar and select the images you want to upload from your computer.\n",
        "\n",
        "Note: All files uploaded in this manner end up in the root of the file tree. We'll move them into the correct spot next."
      ]
    },
    {
      "metadata": {
        "id": "4Bpprb8pRmNh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# e.g. mv ../me.jpg raw_images/\n",
        "!mv ../*.jpg raw_images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aP7AoP2N-Cwh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Align your images"
      ]
    },
    {
      "metadata": {
        "id": "QEQzXr5T-AcB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python align_images.py raw_images aligned_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfIVCApk-JUz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This should produce an image in `aligned_images/` for every image in `raw_images/`.\n",
        "\n",
        "It's a good idea to check that this process worked by using the Files browser to download each aligned image and make sure it looks reasonable. If you encounter scrambled images it might be because your original raw images are too small."
      ]
    },
    {
      "metadata": {
        "id": "93aUSBaNBJDL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Search for your latent self\n",
        "\n",
        "The script `encode_images.py` will minimize the perceptual loss between generated images from StyleGAN and each of the images you've uploaded. (By default this happens one at a time)\n",
        "\n",
        "I've had good results at 1000 iterations and it's best to check the general quality before coming back and ramping up the number of iterations to produce a high-quality latent.\n",
        "\n",
        "Higher quality comes at a cost of course. 10000 iterations will take about **one hour** for one image.\n",
        "\n",
        "**NOTE:** You may get a warning about the GPU memory limit when running this script. Don't worry it will still complete."
      ]
    },
    {
      "metadata": {
        "id": "itkKXoOFLDJg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python encode_images.py aligned_images/ generated_images/ latent_representations/ --iterations 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E6TZovcPCM05",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download Your Results\n",
        "\n",
        "After the above cell has finished writing there should be an image in `generated_images/` for each image in `aligned_images/`.\n",
        "\n",
        "You can right-click and download each of these images to see your final latent self.\n",
        "\n",
        "### Latent Representation\n",
        "\n",
        "You can also download the `npy` files in the `latent_representations/` directory. Each of those is a serialized numpy array which contains the (18, 512) array encoding the point in latent space which corresponds to the generated image. Which you can open with `latent = np.load('filename.npy')`"
      ]
    },
    {
      "metadata": {
        "id": "fhLqYf5RB-ga",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Change your Smile, Gender, or Age\n",
        "\n",
        "Once your latent representation has been generated and saved you can explore the volume around it through latent vectors. Puzer has provided vectors for Smile, Gender and Age so you can see what you look like as your latent self varies along those axes.\n",
        "\n",
        "Run the following cells."
      ]
    },
    {
      "metadata": {
        "id": "S60SiKxu_8AE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "from encoder.generator_model import Generator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PVYrjvgE_8AU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "fd2cfa10-bea0-4ae2-a932-d2152d0caa5f"
      },
      "cell_type": "code",
      "source": [
        "URL_FFHQ = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ'\n",
        "\n",
        "tflib.init_tf()\n",
        "with dnnlib.util.open_url(URL_FFHQ, cache_dir=config.cache_dir) as f:\n",
        "    generator_network, discriminator_network, Gs_network = pickle.load(f)\n",
        "\n",
        "generator = Generator(Gs_network, batch_size=1, randomize_noise=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ .... done\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FY8HzVK5_8Af",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_image(latent_vector):\n",
        "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
        "    generator.set_dlatents(latent_vector)\n",
        "    img_array = generator.generate_images()[0]\n",
        "    img = PIL.Image.fromarray(img_array, 'RGB')\n",
        "    return img #img.resize((256, 256))\n",
        "\n",
        "def move_and_show(latent_vector, direction, coeffs):\n",
        "    fig,ax = plt.subplots(1, len(coeffs), figsize=(15, 10), dpi=80)\n",
        "    for i, coeff in enumerate(coeffs):\n",
        "        new_latent_vector = latent_vector.copy()\n",
        "        new_latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
        "        ax[i].imshow(generate_image(new_latent_vector))\n",
        "        ax[i].set_title('Coeff: %0.1f' % coeff)\n",
        "    [x.axis('off') for x in ax]\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rqYj-P1_8Au",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading already learned representations\n",
        "me = np.load('latent_representations/my_01.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ajPDYVyl_8A1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading already learned latent directions\n",
        "smile_direction = np.load('ffhq_dataset/latent_directions/smile.npy')\n",
        "gender_direction = np.load('ffhq_dataset/latent_directions/gender.npy')\n",
        "age_direction = np.load('ffhq_dataset/latent_directions/age.npy')\n",
        "\n",
        "# In general it's possible to find directions of almost any face attributes: position, hair style or color ... \n",
        "# Additional scripts for doing so will be realised soon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fDhrIyeb_8A8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Smile transformation"
      ]
    },
    {
      "metadata": {
        "id": "g8MPNVhS_8A-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "move_and_show(me, smile_direction, [-0.5, 0, 0.5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1MIV2loD_8Bc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Gender transformation"
      ]
    },
    {
      "metadata": {
        "id": "GHJ5IhqB_8Bg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "move_and_show(me, gender_direction, [-1, 0, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W1ps3yMN_8B5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Age transformation"
      ]
    },
    {
      "metadata": {
        "id": "kwSZcOvG_8B6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "move_and_show(me, age_direction, [-0.5, 0, 0.5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ax2KUotReAti",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  Gs = Gs_network\n",
        "  \n",
        "  # Pick latent vector.\n",
        "  rnd = np.random.RandomState(10)  # seed = 10\n",
        "  latents0 = rnd.randn(1, Gs.input_shape[1])\n",
        "  latents1 = rnd.randn(1, Gs.input_shape[1])\n",
        "  latents2 = rnd.randn(1, Gs.input_shape[1])\n",
        "  latents3 = rnd.randn(1, Gs.input_shape[1])\n",
        "  latents4 = rnd.randn(1, Gs.input_shape[1])\n",
        "  latents5 = rnd.randn(1, Gs.input_shape[1])\n",
        "  latents6 = rnd.randn(1, Gs.input_shape[1])\n",
        "\n",
        "  num_split = 39  # 2つのベクトルを39分割\n",
        "  for i in range(40):\n",
        "      latents = latents6+(latents0-latents6)*i/num_split\n",
        "      # Generate image.\n",
        "      fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "      images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)\n",
        "\n",
        "      # Save image.\n",
        "      os.makedirs(config.result_dir, exist_ok=True)\n",
        "      png_filename = os.path.join(config.result_dir, 'photo'+'{0:04d}'.format(i)+'.png')\n",
        "      PIL.Image.fromarray(images[0], 'RGB').save(png_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F6rzgOThi_AF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        " \n",
        "files = sorted(glob.glob('results/*.png'))\n",
        "images = list(map(lambda file: Image.open(file), files))\n",
        "images[0].save('stylegan.gif', save_all=True, \n",
        "               append_images=images[1:], \n",
        "               duration=200, loop=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gzLIrkUlkCcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url_ffhq        = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n",
        "synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), minibatch_size=8)\n",
        " \n",
        "_Gs_cache = dict()\n",
        " \n",
        "def load_Gs(url):\n",
        "    if url not in _Gs_cache:\n",
        "        with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
        "            _G, _D, Gs = pickle.load(f)\n",
        "        _Gs_cache[url] = Gs\n",
        "    return _Gs_cache[url]\n",
        " \n",
        "# ----------------  Style mixing -------------------\n",
        " \n",
        "def draw_style_mixing_figure(png, Gs, w, h, src_seeds, dst_seeds, style_ranges):\n",
        "    print(png)\n",
        "    src_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in src_seeds)\n",
        "    \n",
        "    d1 = np.random.RandomState(503).randn(Gs.input_shape[1])  # seed = 503 のベクトルを取得\n",
        "    d2 = np.random.RandomState(888).randn(Gs.input_shape[1])  # seed = 888 のベクトルを取得\n",
        "    \n",
        "    dx = (d2 - d1)/3  #　３分割で補間\n",
        "    steps = np.linspace(0,3,4)  # stepsに[0,1,2,3] を代入\n",
        "    dst_latents = np.stack((d1+dx*step) for step in steps)  # dst_latents にベクトルを４つスタック\n",
        "        \n",
        "    src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\n",
        "    dst_dlatents = Gs.components.mapping.run(dst_latents, None) # [seed, layer, component]\n",
        "    src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "    dst_images = Gs.components.synthesis.run(dst_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "    \n",
        "    canvas = PIL.Image.new('RGB', (w * (len(src_seeds) + 1), h * 5), 'white')\n",
        "    for col, src_image in enumerate(list(src_images)):\n",
        "        canvas.paste(PIL.Image.fromarray(src_image, 'RGB'), ((col + 1) * w, 0))\n",
        "    for row, dst_image in enumerate(list(dst_images)):\n",
        "        canvas.paste(PIL.Image.fromarray(dst_image, 'RGB'), (0, (row + 1) * h))  \n",
        "        row_dlatents = np.stack([dst_dlatents[row]] * len(src_seeds))\n",
        "        row_dlatents[:, style_ranges[row]] = src_dlatents[:, style_ranges[row]]\n",
        "        row_images = Gs.components.synthesis.run(row_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "        for col, image in enumerate(list(row_images)):\n",
        "            canvas.paste(PIL.Image.fromarray(image, 'RGB'), ((col + 1) * w, (row + 1) * h)) \n",
        "             \n",
        "    png_filename = os.path.join(config.result_dir, 'style_mix.png')\n",
        "    canvas.save(png_filename)\n",
        " \n",
        "# --------------- main -----------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iy5WrttdklM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b541650b-6026-4686-844d-6e114241abd8"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "tflib.init_tf()\n",
        "os.makedirs(config.result_dir, exist_ok=True)\n",
        "draw_style_mixing_figure(os.path.join(config.result_dir, 'style_mix.png'), load_Gs(url_ffhq), w=1024, h=1024, \n",
        "                                               src_seeds=[11,100,701,583], dst_seeds=[888,829,1898,1733,1614,845], \n",
        "                                               style_ranges=[range(1, 10)]*4)  # style_mixingのレンジ指定\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "results/style_mix.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FOMeCmkgkm3X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}